---
layout: post.html
title: A Simple Framework for Contrastive Learning of Visual Representations
tags: post
date: 2025-10-29T20:12:00
---

# 00:Findings

1. Composition of data augmentation for the data is crucial for contrastive learning tasks.
2. Having a non-linear layer in between the generated representations and the calculated loss improves the quality of the learned representations.
3. Contrastive tasks benefits from larger batch sizes and longer training.

# 01:Introduction
The methods for learning effective visual representations fall into 2 categories:
1. **Generative:** Learn to generate/model pixels in the input space.
2. **Discriminative:** Learn representations using objective functions.

An architecture to introduce a new approach for contrastive learning, using data augmentation and contrastive loss to learn best possible embeddings.

# 02:Architecture
Architecture introduces is named SimCLR, using agreement between different views of the same data with using a contrastive loss.

This architecture is composed of 3 main components:
1. **Data Augmentation:** Series of data transformations applied to create 2 different views of the same data.

$$ \large
\tilde{x}\\_i = t(x\_k) \rightarrow t \sim \mathcal{T}
$$

$$ \large
\tilde{x}\_j = t'(x\_k) \rightarrow t' \sim \mathcal{T}
$$

where:
- $x\_k$: Sampled minibatch $\{ x\_k \}\\_{k=1}^{N}$
- $t$ and $t'$: **Transformation functions** (derived from the same $\mathcal{T}$ transformation set)
- $\tilde{x}\_i$ and $\tilde{x}\_j$: Two views of $x\_k$, described as **positive pairs**

1. **Encoder:** The backbone that extracts the representations from the augmented views of the data.

$$ \large
h\_i = f(\tilde{x}\_i) = \text{ResNet}(\tilde{x}\_i)
$$

2. **Non-Linear Projection Head:** 2-layer Multi-layer Perceptron that maps the representations to a space where the contrastive loss is applied.

$$ \large
z\_i = g(h\_i) = W^{(2)}\ \sigma(W^{(1)}\ h\_i)
$$
where:
- $\sigma( \cdot )$: **ReLU** non-linearity function
- $W^{(n)}$: The **weight matrix** for the layer $n$.

> [!NOTE] Calculating Loss Over the Projection Head
> It’s proven that the **loss calculated over the representations** $z\_i$ generated by the projection head is more beneficial.

3. **Contrastive Loss:** Objective function that is based around the idea of the 2 generated views of the same data being closer to each other than the rest.

## 02.1:Loss
The objective function used is named NT-Xent (Normalized Temperature-scaled Cross Entropy) Loss.

> [!QUOTE] Paper Reference for Contrastive Loss Objective
> Given a **set** $\{ \tilde{x}\_k \}$ including a **positive pair of examples** $\tilde{x}\_i$ and $\tilde{x}\_j$, the contrastive prediction task **aims to identify** $\tilde{x}\_j$ in $\{ \tilde{x}\_k \}\\_{k \neq i}$ for a given $\tilde{x}\_i$.

Given a mini-batch with the size of $N$, 2 views are generated per **image,** resulting with the batch size of $2N$.

### 02.1.1:Loss for Single Anchor
For **positive pairs** $\tilde{x}\_i$ and $\tilde{x}\_j$ – views generated from the **same anchor** $x\_a$, the loss for the anchor is defined as:

$$ \large
\mathscr{l}\_a = -  \log  \Bigg( \frac{ \exp (\ {s\_{cos}( \tilde{x}\_i, \ \tilde{x}\_j )}\ / \  {\tau} \ ) }{ \sum\_{k \ \neq \ a} \exp (\ {s\_{cos}( \tilde{x}\_i, \ \tilde{x}\_k ) }  \ / \  {\tau} \ ) } \Bigg)
$$

where:
- $\exp$: Exponential Function
- $s\_{cos}(\cdot)$: Cosine Similarity
$$ \large
s\_{cos}  ( \tilde{x}\_i, \ \tilde{x}\_j ) = \frac{ {\tilde{x}^{\top}\_i} \ \tilde{x}\_j }{|| \tilde{x}\_i || \ || \tilde{x}\_j ||}
$$
- $\tau$: Temperature

### 02.1.2:Loss for the Mini-batch
The **full loss** averages over all the $2N$ anchors in the mini-batch:

$$ \large
\mathscr{L} = \frac{1}{2N} \sum\_{a=1}^{2N} \mathscr{l}\_a 
$$
